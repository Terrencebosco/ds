{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code_for_API_Endpoint.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9LNFF4gt4g2"
      },
      "source": [
        "# Required dependencies\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from collections import OrderedDict\n",
        "import json\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YgvLPhYuB5x"
      },
      "source": [
        "# Read in tier 1 and tier 2 category lookup data\n",
        "subreddit_info = pd.read_csv('subreddit_info_cleaned.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74VsrgQ6rtYe"
      },
      "source": [
        "# Load serialized model\n",
        "restored_model = load_model('keras_pred_subreddit_model_v5.h5')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgp3Z4u6r6Bi"
      },
      "source": [
        "# Load serialized tokenizer\n",
        "with open('keras_tokenizer_v5.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISk9_VGgsDIL"
      },
      "source": [
        "# Load serialized label encoder\n",
        "with open('sklearn_label_encoder_v5.pickle', 'rb') as handle:\n",
        "    encoder = pickle.load(handle)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIfy9ewWsNLl"
      },
      "source": [
        "maxlen = 250 # DO NOT MODIFY THIS\n",
        "\n",
        "def predict_on_new(input, tokenizer=tokenizer, restored_model=restored_model, \n",
        "                   maxlen=maxlen, encoder=encoder):\n",
        "  '''This function takes an input as a string (Web will hit our API endpoint) \n",
        "  and returns (in JSON format) the top five subreddit predictions along with \n",
        "  each subreddit's tier 1 and tier 2 categories'''\n",
        "  seq = tokenizer.texts_to_sequences([input])\n",
        "  pad_seq = sequence.pad_sequences(seq, maxlen=maxlen)\n",
        "  pred = restored_model.predict(pad_seq)\n",
        "  class_names = list(encoder.inverse_transform(pred[0].argsort()[-5:][::-1]))\n",
        "\n",
        "  t1_category = []\n",
        "  t2_category = []\n",
        "\n",
        "  pred_key = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
        "\n",
        "  for c in class_names:\n",
        "    for i, sub_red in enumerate(subreddit_info['subreddit']):\n",
        "      if sub_red == c:\n",
        "        t1_cat = subreddit_info['category_1'].iloc[i]\n",
        "        t1_category.append(t1_cat)\n",
        "        t2_cat = subreddit_info['category_2'].iloc[i]\n",
        "        t2_category.append(t2_cat)\n",
        "\n",
        "  pred_dict = OrderedDict(zip(pred_key, zip(class_names, zip(t1_category, t2_category))))\n",
        "  return json.dumps(pred_dict)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-SX21lDtFWa",
        "outputId": "a66cffa7-427a-45f6-d1c9-6975bd31e54a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Example of above function call\n",
        "\n",
        "# String from web hitting our API endpoint\n",
        "string_from_web = '''Was in Vegas this weekend and hit up Speed Vegas. My plan \n",
        "originally was to drive the C8 but this time I could afford the Ferrari so I \n",
        "went with that and I don't regret my decision at all. Driving a Ferrari was a \n",
        "childhood dream come true and its something I'll never forget as long as I live.\n",
        "The car was super easy to drive and get used to. After the first lap I felt right \n",
        "at home with how it drove. Hitting those turns at 55-60mph without having to \n",
        "brake or put the gas was amazing. This car handled those turns like a champ and \n",
        "I was shocked at how good it was at taking those turns. On the straight-away I \n",
        "hit 142mph and it got up to that speed super quick. The sound of the engine right \n",
        "behind your head screaming as your floor it is something that you gotta hear.'''\n",
        "\n",
        "# Prediction JSON returned to web\n",
        "predict_on_new(string_from_web)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"pred_1\": [\"formula1\", [\"sports\", \"formula 1\"]], \"pred_2\": [\"mazda3\", [\"autos\", \"mazda\"]], \"pred_3\": [\"driving\", [\"hobby\", \"driving\"]], \"pred_4\": [\"Mustang\", [\"autos\", \"ford\"]], \"pred_5\": [\"needforspeed\", [\"video_game\", \"need for speed\"]]}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}